**国产超算科研课堂中期汇报答辩稿**  
**汇报题目：DDQ-基于数据流图的卷积神经网络并行实现**  
**汇报人：吴震宏**  
**时间：10分钟**  

---

### **1. 开场与背景介绍（1.5分钟）**  

尊敬的各位老师、同学：  
大家好！我是吴震宏，今天很荣幸向大家汇报我们在国产超算平台上基于DDQ框架的卷积神经网络并行化研究工作，我的指导学长是韩斌。

---
我的汇报将分为五个部分：
1. 研究背景与目标
2. 研究内容
3. 技术路线
4. 串行实现与实验结果
5. 中期总结与展望

---

首先，让我们来看一下研究的背景。在后摩尔时代，随着晶体管尺寸逼近物理极限，单纯依靠工艺提升性能变得越来越困难。异构多核处理器成为主流架构，不同核心在计算和存储能力上存在显著差异。传统的基于循环的并行方案在处理数据依赖复杂、有环图控制时，扩展性和性能受到严重限制。  

而图驱动的数据流模型为我们提供了新的思路。以DDQ框架为例，它通过有向有环图灵活表达算子和数据依赖关系，特别适合计算密集型的CNN任务。我们的研究目标是利用DDQ的自动调度能力，探索一种既能便捷推导依赖关系，又能高效调度的并行框架，最终实现CNN"层间串行、层内并行"的高效执行模式。  

---
### **2. 研究内容与技术路线（4分钟）**  

#### **DDQ框架核心思想**  
DDQ框架的优势在于数据流图表示和调度机制。让我们深入剖析几个关键点：  

首先，**算子图表示**方面，DDQ将每个计算任务抽象为图中的节点，数据依赖关系表示为边。例如，在我们的CNN实现中，卷积算子、激活算子、池化算子都作为独立节点，它们之间的数据流动构成了完整的前向传播链。

其次，**状态驱动机制**是DDQ的调度核心。每个算子执行后会返回状态值，如`ok`表示正常完成，`done`表示终止，`partial`表示部分完成。调度器根据这些状态从就绪队列中依次取出并执行。同时，数据对象也通过标记其状态属性，确保数据依赖的正确性。  

---

#### **CNN并行设计策略**  
通过分析卷积神经网络各层之间的依赖关系，我们确定了“层间串行、层内并行”策略。基于DDQ的特性，设计了两级并行策略：  

1. **算子内部分片并行**：  
   - 我们的主要任务是挖掘CNN各层内部的并行点，实现更高效的并行计算。 
   - 在卷积层，我们按通道维度切分输入特征图，由不同线程并行处理。  
   - 对于矩阵乘法采用分块策略，加速计算。  

2. **微批次流水线并行**：  
   - 将CNN各层调度给不同的处理器核心，形成流水线并行。

---

### **3. 串行实现与实验结果（3.5分钟）**  
**（翻至PPT第6-9页）**  
#### **串行CNN实现**  
在进入并行优化前，我们首先完成了DDQ上的串行CNN实现，这是后续工作的基础。这个实现包含5类核心算子：  

1. **卷积算子(t_conv)**：接受输入缓冲或上一层池化输出，使用指定卷积核进行运算  
2. **激活算子(t_relu)**：对卷积输出逐元素应用激活函数
3. **池化算子(t_pool)**：在2×2窗口上进行最大池化  
4. **全连接算子(t_fc)**：将最终特征图展平为一维向量  
5. **打印算子**：用于输出结果  


---

#### **关键代码流程**  
我们的代码从文件读取输入和卷积核，初始化CNN环并动态分配各层矩阵，通过DDQ任务图执行CNN计算流程，输出结果，最后释放资源。
CNN计算内部则采用了循环结构，逐层执行卷积、激活、池化和全连接操作。以下是关键代码片段

--- 
可以看到，算子通过DDQ的`ddq_spawn`函数创建，并通过`ddq_add_inputs`和`ddq_add_outputs`进行输入输出绑定。

---
#### **实验结果**  
我们使用16×16输入矩阵和3×3卷积核进行测试，成功实现了：  
- **指定输入和卷积核**：读取输入矩阵和卷积核并动态计算各层尺寸，自动分配内存
- **实现指定次数的卷积循环**：在执行2次后终止循环 
- **全连接输出**：最终展平为1×4向量，得到结果`[20.95, 21.71, 33.20, 33.96]`  
- **内存管理**：所有中间矩阵都正确分配和释放，确保无内存泄漏

---

### **5. 总结与展望（1分钟）**  
**（翻至PPT第10、12页）**  
总结来说，我们已经完成了以下工作：  
✅ 基于DDQ框架成功完成串行CNN实现
✅ 完成了动态尺寸计算与内存管理机制，验证了各算子的正确性和功能性  
✅ 基本实现多层前向传播功能验证 

这为后续的并行化工作夯实了基础

---

### **4. 优化方向与挑战（2分钟）**  
**（翻至PPT第11页）**  
下一步我们将重点突破以下方向：  

1. **算子内部分片优化**：  
   - 卷积层采用多线程窗口计算，每个线程处理局部区域  
   - 探索更多快速卷积方法  

2. **流水线并行实现**：  
   - 通过DDQ的`ddq_spawn`将各层拆分为独立算子节点，分配到不同异构核心
   - 尝试设计高效的流水线处理机制

3. **混合并行策略**：  
   - 结合分片和流水线两种并行模式  
   - 协同优化突破单层算力瓶颈
   - 进行对比实验，验证性能提升  
我们预计的主要挑战包括：  
- 数据依赖关系的精确控制
- 并行模式下的正确性验证  
---

最后，感谢老师和学长的悉心指导，我将在后续工作中继续跟进，也欢迎大家提出宝贵意见！  
